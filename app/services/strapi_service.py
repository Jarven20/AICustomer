import os
import json
import requests
import httpx
from app.core.config import settings
import chromadb
from chromadb.config import Settings
from openai import OpenAI
from tqdm import tqdm
import time
import tempfile
import shutil
from datetime import datetime, timedelta
from app.services.cleanup import delete_update_file

class StrapiService:
    def __init__(self):
        """åˆå§‹åŒ– Strapi æœåŠ¡"""
        self.base_url = settings.STRAPI_API_URL
        self.api_token = settings.STRAPI_API_TOKEN
        self.headers = {
            "Authorization": f"Bearer {self.api_token}",
            "Content-Type": "application/json"
        }
    
        # åˆ›å»ºæ•°æ®å­˜å‚¨ç›®å½• - ä¿®æ”¹ä¸º app ç›®å½•ä¸‹çš„ data æ–‡ä»¶å¤¹
        self.data_dir = os.path.join(os.path.dirname(os.path.dirname(__file__)), "data")
        if not os.path.exists(self.data_dir):
            os.makedirs(self.data_dir)
        os.chmod(self.data_dir, 0o777)
            
        # åˆ›å»º ChromaDB æ•°æ®ç›®å½•
        self.chroma_db_path = os.path.join(self.data_dir, "chroma_db")
        if not os.path.exists(self.chroma_db_path):
            os.makedirs(self.chroma_db_path)
            print(f"âœ… åˆ›å»º ChromaDB æ•°æ®ç›®å½•: {self.chroma_db_path}")
        os.chmod(self.chroma_db_path, 0o777)
            
        # åˆå§‹åŒ– ChromaDB
        print(f"\nğŸ”§ åˆå§‹åŒ– ChromaDB å®¢æˆ·ç«¯...")
        print(f"æ•°æ®ç›®å½•: {self.chroma_db_path}")
        
        # ç¡®ä¿æ‰€æœ‰ç°æœ‰æ–‡ä»¶å’Œç›®å½•éƒ½æœ‰æ­£ç¡®çš„æƒé™
        for root, dirs, files in os.walk(self.chroma_db_path):
            for d in dirs:
                os.chmod(os.path.join(root, d), 0o777)
            for f in files:
                os.chmod(os.path.join(root, f), 0o777)
        
        self.chroma_client = chromadb.PersistentClient(
            path=self.chroma_db_path,
            settings=Settings(
                anonymized_telemetry=False,
                allow_reset=True,
                persist_directory=self.chroma_db_path,
                is_persistent=True
            )
        )
        print("âœ… ChromaDB å®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
        
        # åˆå§‹åŒ– OpenAI å®¢æˆ·ç«¯
        self.openai_api_key = settings.OPENAI_API_KEY
        if not self.openai_api_key:
            print("âš ï¸ è­¦å‘Š: æœªè®¾ç½® OPENAI_API_KEY ç¯å¢ƒå˜é‡")
            
        print(f"\nğŸ”§ OpenAI å®¢æˆ·ç«¯åˆå§‹åŒ–:")
        print(f"OpenAI API Key å·²è®¾ç½®: {'âœ… æ˜¯' if self.openai_api_key else 'âŒ å¦'}")
        print(f"OpenAI API URL: {settings.OPENAI_API_URL}")
        
        # åˆå§‹åŒ– OpenAI å®¢æˆ·ç«¯
        self.openai_client = OpenAI(
            api_key=self.openai_api_key,
            base_url=settings.OPENAI_API_URL,
            default_headers={"x-auth-key": settings.OPENAI_AUTH_KEY},
            http_client=httpx.Client(
                verify=False  # å¦‚æœæœ‰ SSL è¯ä¹¦é—®é¢˜ï¼Œå¯ä»¥ç¦ç”¨éªŒè¯
            )
        )
            
        # æ‰“å°é…ç½®ä¿¡æ¯ï¼ˆä¸åŒ…å«æ•æ„Ÿä¿¡æ¯ï¼‰
        print(f"\nStrapi æœåŠ¡åˆå§‹åŒ–:")
        print(f"API URL: {self.base_url}")
        print(f"æ•°æ®ç›®å½•: {self.data_dir}")
        print(f"API Token å·²è®¾ç½®: {'âœ… æ˜¯' if self.api_token else 'âŒ å¦'}")
        print(f"OpenAI API Key å·²è®¾ç½®: {'âœ… æ˜¯' if self.openai_api_key else 'âŒ å¦'}")
        print(f"ChromaDB æŒä¹…åŒ–ç›®å½•: {self.chroma_db_path}")
    
    def get_all_knowledge(self, endpoint="api/im-customer-service-knowledge-bases", params=None):  #å½“ endpoint ä¸ºç©ºå­—ç¬¦ä¸²æ—¶ï¼ŒURL å°±åªä¼šä½¿ç”¨ base_urlï¼Œä¸ä¼šæ·»åŠ é¢å¤–çš„è·¯å¾„
        """
        è·å–æ‰€æœ‰çŸ¥è¯†ç‚¹æ•°æ®ï¼ˆåˆ†é¡µå¤„ç†ï¼‰  ä¸­é—´å‡½æ•°ï¼Œè¢«fetch_and_save_knowledgeè°ƒç”¨
        
        Args:
            endpoint (str): API ç«¯ç‚¹ï¼Œä¾‹å¦‚ 'api/knowledge-base'
            params (dict, optional): è¯·æ±‚å‚æ•°
            
        Returns:
            list: æ‰€æœ‰è·å–åˆ°çš„æ•°æ®
        """
        if params is None:
            params = {}
        
        all_data = []
        page = 1
        page_size = 100  # æ¯é¡µæ•°æ®é‡
        total_pages = 1  # åˆå§‹å€¼ï¼Œä¼šåœ¨ç¬¬ä¸€æ¬¡è¯·æ±‚åæ›´æ–°
        
        while page <= total_pages:
            # æ›´æ–°åˆ†é¡µå‚æ•°
            current_params = {
                **params,
                'pagination[page]': page,
                'pagination[pageSize]': page_size
            }
            
            try:
                # æ„å»ºå®Œæ•´çš„ URLï¼Œç¡®ä¿ä¸ä¼šå‡ºç°åŒæ–œæ 
                base_url = self.base_url.rstrip('/')
                endpoint = endpoint.lstrip('/')
                url = f"{base_url}/{endpoint}"
                print(f"\nå°è¯•è¿æ¥: {url}")
                print(f"è¯·æ±‚å‚æ•°: {current_params}")
                
                # å‘é€è¯·æ±‚
                response = requests.get(
                    url,
                    params=current_params,
                    headers=self.headers,
                    timeout=30,
                    verify=False  # ä¸´æ—¶ç¦ç”¨ SSL éªŒè¯ï¼Œç”¨äºè°ƒè¯•
                )
                
                # æ‰“å°å“åº”ä¿¡æ¯
                print(f"å“åº”çŠ¶æ€ç : {response.status_code}")
                print(f"å“åº”å¤´: {dict(response.headers)}")
                
                response.raise_for_status()
                
                result = response.json()
                
                # æå–æ•°æ®
                if 'data' in result and isinstance(result['data'], list):
                    all_data.extend(result['data'])
                    print(f"æˆåŠŸè·å– {len(result['data'])} æ¡æ•°æ®")
                else:
                    print("è­¦å‘Š: å“åº”ä¸­æ²¡æœ‰æ‰¾åˆ° data å­—æ®µæˆ–ä¸æ˜¯åˆ—è¡¨ç±»å‹")
                    print(f"å“åº”å†…å®¹: {result}")
                
                # æ›´æ–°æ€»é¡µæ•°
                if 'meta' in result and 'pagination' in result['meta']:
                    pagination = result['meta']['pagination']
                    total_pages = pagination.get('pageCount', 1)
                    print(f"è·å–ç¬¬ {page}/{total_pages} é¡µï¼Œæ¯é¡µ {page_size} æ¡ï¼Œæ€»è®¡ {pagination.get('total', 0)} æ¡æ•°æ®")
                else:
                    print("è­¦å‘Š: å“åº”ä¸­æ²¡æœ‰æ‰¾åˆ°åˆ†é¡µä¿¡æ¯")
                
                page += 1
                
            except requests.exceptions.SSLError as e:
                print(f"SSL è¯ä¹¦éªŒè¯é”™è¯¯: {str(e)}")
                print("è¯·æ£€æŸ¥ API URL æ˜¯å¦æ­£ç¡®ï¼Œæˆ–ç¡®ä¿æœåŠ¡å™¨è¯ä¹¦æœ‰æ•ˆ")
                break
            except requests.exceptions.ConnectionError as e:
                print(f"è¿æ¥é”™è¯¯: {str(e)}")
                print("è¯·æ£€æŸ¥:")
                print("1. Strapi æœåŠ¡å™¨æ˜¯å¦æ­£åœ¨è¿è¡Œ")
                print("2. API URL æ˜¯å¦æ­£ç¡®")
                print("3. ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸")
                break
            except requests.exceptions.Timeout as e:
                print(f"è¯·æ±‚è¶…æ—¶: {str(e)}")
                print("è¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–å¢åŠ è¶…æ—¶æ—¶é—´")
                break
            except requests.exceptions.RequestException as e:
                print(f"è¯·æ±‚é”™è¯¯: {str(e)}")
                print(f"å“åº”å†…å®¹: {getattr(e.response, 'text', 'æ— å“åº”å†…å®¹')}")
                break
            except Exception as e:
                print(f"è·å–æ•°æ®å¤±è´¥ï¼ˆé¡µç  {page}ï¼‰: {str(e)}")
                break
        
        return all_data
    
    def save_to_json(self, data, filename):
        """
        å°†æ•°æ®ä¿å­˜ä¸º JSON æ–‡ä»¶  ä¸­é—´å‡½æ•°ï¼Œè¢«fetch_and_save_knowledgeè°ƒç”¨
        
        Args:
            data: è¦ä¿å­˜çš„æ•°æ®
            filename (str): æ–‡ä»¶å
            
        Returns:
            str: ä¿å­˜çš„æ–‡ä»¶è·¯å¾„
        """
        filepath = os.path.join(self.data_dir, filename)
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        
        print(f"æ•°æ®å·²ä¿å­˜åˆ°: {filepath}")
        return filepath
    
    def fetch_and_save_knowledge(self, endpoint="api/im-customer-service-knowledge-bases", params=None):
        """
        è·å–å¹¶ä¿å­˜æ‰€æœ‰çŸ¥è¯†ç‚¹æ•°æ®  ä¸­é—´å‡½æ•°ï¼Œè¢«store_faq_in_chromadbè°ƒç”¨
        
        Args:
            endpoint (str): API ç«¯ç‚¹
            params (dict, optional): é¢å¤–çš„è¯·æ±‚å‚æ•°
            
        Returns:
            str: ä¿å­˜çš„æ–‡ä»¶è·¯å¾„
        """
        if params is None:
            params = {}
            
        # æ·»åŠ  populate å‚æ•°ä»¥è·å–å®Œæ•´æ•°æ®
        params['populate'] = '*'
        
        # è·å–æ‰€æœ‰æ•°æ®
        all_data = self.get_all_knowledge(endpoint, params)
        
        # æ„å»ºå®Œæ•´æ•°æ®ç»“æ„
        full_data = {
            "data": all_data,
            "meta": {
                "pagination": {
                    "page": 1,
                    "pageSize": len(all_data),
                    "pageCount": 1,
                    "total": len(all_data)
                }
            }
        }
        
        # ä¿å­˜ä¸º JSON æ–‡ä»¶ - ä½¿ç”¨å›ºå®šçš„æ–‡ä»¶å
        # return self.save_to_json(full_data, f"{endpoint.replace('/', '_')}_full.json")
        return self.save_to_json(full_data, "strapi_knowledge_full.json") # <-- ä¿®æ”¹æ–‡ä»¶å
    
    def parse_knowledge_json(self, input_file="strapi_knowledge_full.json", output_file="strapi_knowledge_parsed.json"): # <-- ä¿®æ”¹é»˜è®¤æ–‡ä»¶å
        """
        è§£æçŸ¥è¯†åº“ JSON æ–‡ä»¶ï¼Œæå–æŒ‡å®šå­—æ®µå¹¶ç”Ÿæˆæ–°æ–‡ä»¶  ä¸­é—´å‡½æ•°ï¼Œè¢«store_faq_in_chromadbè°ƒç”¨
        
        Args:
            input_file (str): è¾“å…¥çš„ JSON æ–‡ä»¶å
            output_file (str): è¾“å‡ºçš„ JSON æ–‡ä»¶å
            
        Returns:
            str: è¾“å‡ºæ–‡ä»¶çš„å®Œæ•´è·¯å¾„
        """
        try:
            # æ„å»ºè¾“å…¥å’Œè¾“å‡ºæ–‡ä»¶çš„å®Œæ•´è·¯å¾„
            input_filepath = os.path.join(self.data_dir, input_file)
            output_filepath = os.path.join(self.data_dir, output_file)
            
            # æ£€æŸ¥è¾“å…¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not os.path.exists(input_filepath):
                raise FileNotFoundError(f"è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {input_filepath}")
            
            # è¯»å–è¾“å…¥æ–‡ä»¶
            with open(input_filepath, 'r', encoding='utf-8') as f:
                data = json.load(f)

            print(f"æˆåŠŸè¯»å– {len(data)} æ¡æ•°æ®")
            
            # æå–æŒ‡å®šå­—æ®µ
            parsed_data = []
            empty_faq_count = 0
            
            if 'data' in data:
                for item in data['data']:
                    attributes = item.get('attributes', {})
                    faq = attributes.get('FAQ', '')
                    
                    # è·³è¿‡FAQä¸ºç©ºçš„æ¡ç›®æˆ–å°†å…¶æ ‡è®°ä¸ºéœ€è¦æ³¨æ„
                    if faq is None or faq.strip() == '':
                        empty_faq_count += 1
                        # å¯ä»¥é€‰æ‹©è·³è¿‡æˆ–è€…ä¿ç•™ï¼Œè¿™é‡Œæˆ‘ä»¬ä¿ç•™ä½†æ˜¯ç”¨ç©ºå­—ç¬¦ä¸²
                        faq = ''
                    
                    # æå–å›¾ç‰‡URLï¼ˆä¼˜å…ˆå–å¤§å›¾ï¼‰
                    app_image_url = self._extract_large_image_url(attributes.get('Response_Pic_App', {}))
                    pc_image_url = self._extract_large_image_url(attributes.get('Response_Pic_Pc', {}))
                        
                    parsed_item = {
                        'id': item.get('id'),
                        'FAQ': faq,
                        'Keywords': attributes.get('Keywords', ''),
                        'Response': attributes.get('Response', ''),  # æ·»åŠ Responseå­—æ®µ
                        'Response_Pic_App_URL': app_image_url,  # æ·»åŠ ç§»åŠ¨ç«¯å›¾ç‰‡URL
                        'Response_Pic_Pc_URL': pc_image_url     # æ·»åŠ PCç«¯å›¾ç‰‡URL
                    }
                    parsed_data.append(parsed_item)
            
            # ä¿å­˜è§£æåçš„æ•°æ®
            with open(output_filepath, 'w', encoding='utf-8') as f:
                json.dump(parsed_data, f, ensure_ascii=False, indent=2)
            
            print(f"æˆåŠŸè§£ææ•°æ®å¹¶ä¿å­˜åˆ°: {output_filepath}")
            print(f"å…±å¤„ç† {len(parsed_data)} æ¡æ•°æ®")
            if empty_faq_count > 0:
                print(f"âš ï¸ è­¦å‘Š: æœ‰ {empty_faq_count} æ¡æ•°æ®çš„FAQå­—æ®µä¸ºç©º")
            
            return output_filepath
            
        except Exception as e:
            print(f"è§£æ JSON æ–‡ä»¶å¤±è´¥: {str(e)}")
            return None

    def get_embedding(self, text):
        """
        ä½¿ç”¨ OpenAI è·å–æ–‡æœ¬çš„ embedding  ä¸­é—´å‡½æ•°ï¼Œè¢«store_faq_in_chromadbè°ƒç”¨
        
        Args:
            text (str): è¦è·å– embedding çš„æ–‡æœ¬
            
        Returns:
            list: embedding å‘é‡
        """
        if not self.openai_api_key:
            print("âŒ é”™è¯¯: æœªè®¾ç½® OPENAI_API_KEY ç¯å¢ƒå˜é‡")
            return None
            
        max_retries = 5  # å¢åŠ é‡è¯•æ¬¡æ•°
        retry_delay = 2  # å¢åŠ åˆå§‹å»¶è¿Ÿæ—¶é—´
        max_delay = 32   # æœ€å¤§å»¶è¿Ÿæ—¶é—´
        
        for attempt in range(max_retries):
            try:
                print(f"ğŸ“¡ æ­£åœ¨è·å–æ–‡æœ¬ embedding (å°è¯• {attempt + 1}/{max_retries})...")
                # å¢åŠ è¶…æ—¶æ—¶é—´åˆ° 60 ç§’
                response = self.openai_client.embeddings.create(
                    model="text-embedding-ada-002",
                    input=text,
                    timeout=5  # è®¾ç½® 5 ç§’è¶…æ—¶
                )
                print("âœ… æˆåŠŸè·å– embedding")
                return response.data[0].embedding
            except Exception as e:
                error_msg = str(e)
                if "api_key" in error_msg.lower():
                    print("âŒ OpenAI API Key æ— æ•ˆæˆ–æœªæ­£ç¡®è®¾ç½®")
                    print("è¯·æ£€æŸ¥ OPENAI_API_KEY ç¯å¢ƒå˜é‡æ˜¯å¦æ­£ç¡®è®¾ç½®")
                    return None
                elif "rate limit" in error_msg.lower():
                    print("âš ï¸ API è°ƒç”¨é¢‘ç‡è¶…é™")
                    if attempt < max_retries - 1:
                        current_delay = min(retry_delay * (2 ** attempt), max_delay)  # æŒ‡æ•°é€€é¿ï¼Œä½†ä¸è¶…è¿‡æœ€å¤§å»¶è¿Ÿ
                        print(f"ç­‰å¾… {current_delay} ç§’åé‡è¯•...")
                        time.sleep(current_delay)
                    continue
                elif "timeout" in error_msg.lower():
                    print("âš ï¸ è¯·æ±‚è¶…æ—¶")
                    if attempt < max_retries - 1:
                        current_delay = min(retry_delay * (2 ** attempt), max_delay)
                        print(f"ç­‰å¾… {current_delay} ç§’åé‡è¯•...")
                        time.sleep(current_delay)
                    continue
                else:
                    if attempt < max_retries - 1:
                        print(f"âŒ è·å– embedding å¤±è´¥ (å°è¯• {attempt + 1}/{max_retries})")
                        print(f"é”™è¯¯ä¿¡æ¯: {error_msg}")
                        current_delay = min(retry_delay * (2 ** attempt), max_delay)
                        print(f"ç­‰å¾… {current_delay} ç§’åé‡è¯•...")
                        time.sleep(current_delay)
                    else:
                        print(f"âŒ è·å– embedding æœ€ç»ˆå¤±è´¥")
                        print(f"é”™è¯¯ä¿¡æ¯: {error_msg}")
                        print("è¯·æ£€æŸ¥:")
                        print("1. ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸")
                        print("2. OpenAI API æœåŠ¡æ˜¯å¦å¯ç”¨")
                        print("3. API Key æ˜¯å¦æœ‰è¶³å¤Ÿçš„é…é¢")
                        print("4. æ˜¯å¦éœ€è¦ä½¿ç”¨ä»£ç†æœåŠ¡å™¨")
                        return None

    def store_faq_in_chromadb(self, recreate_collection=True):
        """
        å°†FAQä¿¡æ¯å­˜å‚¨åˆ°ChromaDB  ä¸»å‡½æ•°ï¼Œè¢«main.pyè°ƒç”¨
        
        Args:
            recreate_collection (bool): æ˜¯å¦é‡æ–°åˆ›å»ºé›†åˆï¼Œé»˜è®¤ä¸ºTrue
            
        Returns:
            bool: æ˜¯å¦æˆåŠŸå­˜å‚¨
        """
        try:
            print("\nğŸ“¥ å¼€å§‹å°†FAQæ•°æ®å­˜å‚¨åˆ°ChromaDB...")
            
            # åŠ è½½è§£æåçš„çŸ¥è¯†åº“æ•°æ®
            json_path = os.path.join(self.data_dir, "strapi_knowledge_parsed.json")
            if not os.path.exists(json_path):
                print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°çŸ¥è¯†åº“æ–‡ä»¶ {json_path}")
                return False
                
            with open(json_path, 'r', encoding='utf-8') as f:
                knowledge_data = json.load(f)
                
            print(f"ğŸ“š ä» {json_path} åŠ è½½äº† {len(knowledge_data)} æ¡é—®ç­”æ•°æ®")
            
            # å‡†å¤‡é›†åˆ
            if recreate_collection:
                print("ğŸ—‘ï¸ é‡æ–°åˆ›å»ºé›†åˆ 'im-customer-service'...")
                # å¦‚æœé›†åˆå·²å­˜åœ¨ï¼Œåˆ™åˆ é™¤
                try:
                    self.chroma_client.delete_collection('im-customer-service')
                    print("âœ… æˆåŠŸåˆ é™¤ç°æœ‰é›†åˆ")
                except Exception as e:
                    print(f"â„¹ï¸ åˆ é™¤é›†åˆæ—¶å‡ºç°æ¶ˆæ¯: {str(e)}")
                
                # åˆ›å»ºæ–°é›†åˆ
                collection = self.chroma_client.create_collection(
                    name='im-customer-service',
                    metadata={"description": "IMå®¢æœçŸ¥è¯†åº“ï¼Œç”¨äºAIåŠ©æ‰‹ç”Ÿæˆå›ç­”ã€‚"},
                    embedding_function=self._get_embedding_function()  # ä½¿ç”¨è‡ªå®šä¹‰åµŒå…¥å‡½æ•°
                )
                print("âœ… æˆåŠŸåˆ›å»ºæ–°é›†åˆ")
            else:
                # è·å–æˆ–åˆ›å»ºé›†åˆ
                try:
                    collection = self.chroma_client.get_collection(
                        name='im-customer-service',
                        embedding_function=self._get_embedding_function()  # ä½¿ç”¨è‡ªå®šä¹‰åµŒå…¥å‡½æ•°
                    )
                    print("âœ… æˆåŠŸè·å–ç°æœ‰é›†åˆ")
                except Exception as e:
                    print(f"â„¹ï¸ è·å–é›†åˆæ—¶å‡ºç°æ¶ˆæ¯: {str(e)}")
                    collection = self.chroma_client.create_collection(
                        name='im-customer-service',
                        metadata={"description": "IMå®¢æœçŸ¥è¯†åº“ï¼Œç”¨äºAIåŠ©æ‰‹ç”Ÿæˆå›ç­”ã€‚"},
                        embedding_function=self._get_embedding_function()  # ä½¿ç”¨è‡ªå®šä¹‰åµŒå…¥å‡½æ•°
                    )
                    print("âœ… é›†åˆä¸å­˜åœ¨ï¼Œå·²åˆ›å»ºæ–°é›†åˆ")
            
            # é¢„å¤„ç†æ•°æ®ï¼šå°†çŸ¥è¯†æ•°æ®è½¬æ¢ä¸ºFAQæ–‡æœ¬
            print("ğŸ” æ­£åœ¨é¢„å¤„ç†FAQæ•°æ®...")
            texts = []      # å­˜å‚¨FAQæ–‡æœ¬
            metadatas = []  # å­˜å‚¨å…ƒæ•°æ®
            ids = []        # å­˜å‚¨å”¯ä¸€ID
            
            for item in knowledge_data:
                # è·å–IDï¼Œç¡®ä¿ä¸ºå­—ç¬¦ä¸²ç±»å‹
                item_id = str(item.get('id', ''))
                
                # æå–FAQã€å…³é”®è¯ã€å›ç­”æ–‡æœ¬
                faq = item.get('FAQ', '')
                keywords = item.get('Keywords', '')
                response = item.get('Response', '')
                
                # è®°å½•å¯èƒ½çš„ç©ºå€¼
                if faq is None or faq == '':
                    print(f"âš ï¸ è­¦å‘Š: IDä¸º {item_id} çš„FAQå†…å®¹ä¸ºç©º")
                
                # ç»„åˆä¸ºå®Œæ•´çš„FAQæ–‡æœ¬ç”¨äºå‘é‡æ£€ç´¢
                # æ³¨æ„ï¼šè¿™é‡Œä¸åŒ…å«Responseï¼Œå› ä¸ºé—®ç­”åŒ¹é…ä¸»è¦åŸºäºé—®é¢˜å’Œå…³é”®è¯
                # ä½†åœ¨å…ƒæ•°æ®ä¸­åŒ…å«äº†å®Œæ•´ä¿¡æ¯
                faq_text_list = self.preprocess_faq_text(faq)
                if not faq_text_list:  # æ£€æŸ¥åˆ—è¡¨æ˜¯å¦ä¸ºç©º
                    print(f"âš ï¸ è­¦å‘Š: IDä¸º {item_id} çš„FAQå¤„ç†åä¸ºç©ºï¼Œè·³è¿‡")
                    continue  # è·³è¿‡ç©ºå†…å®¹
                
                # å°†åˆ—è¡¨è¿æ¥ä¸ºå­—ç¬¦ä¸²ç”¨äºå­˜å‚¨
                faq_text = "\n".join(faq_text_list)
                
                # ç›´æ¥åµŒå…¥FAQæ–‡æœ¬
                # embedding = self.get_embedding(faq_text)
                # if embedding is None:
                #     print(f"âš ï¸ è­¦å‘Š: æ— æ³•è·å–IDä¸º {item_id} çš„åµŒå…¥å‘é‡ï¼Œè·³è¿‡")
                #     continue
                
                # å‡†å¤‡å…ƒæ•°æ®
                metadata = {
                    "id": item_id,
                    "faq": faq if faq is not None else "",
                    "keywords": keywords if keywords is not None else "",
                    "response": response if response is not None else ""
                }
                
                texts.append(faq_text)
                metadatas.append(metadata)
                ids.append(f"faq_{item_id}")
            
            if not texts:
                print("âŒ é”™è¯¯: æ²¡æœ‰æœ‰æ•ˆçš„FAQæ•°æ®")
                return False
                
            print(f"âœ… é¢„å¤„ç†å®Œæˆï¼Œå…±æœ‰ {len(texts)} æ¡FAQæ•°æ®å‡†å¤‡åŠ å…¥å‘é‡æ•°æ®åº“")
            
            # åˆ†æ‰¹å¤„ç†ï¼Œæ¯æ‰¹100æ¡
            batch_size = 100
            batches = (len(texts) + batch_size - 1) // batch_size  # å‘ä¸Šå–æ•´
            
            for i in range(batches):
                start_idx = i * batch_size
                end_idx = min(start_idx + batch_size, len(texts))
                
                print(f"ğŸ”„ å¤„ç†æ‰¹æ¬¡ {i+1}/{batches}ï¼Œé¡¹ç›® {start_idx}-{end_idx-1}...")
                
                batch_texts = texts[start_idx:end_idx]
                batch_metadatas = metadatas[start_idx:end_idx]
                batch_ids = ids[start_idx:end_idx]
                
                # æ·»åŠ åˆ°ChromaDB
                collection.add(
                    documents=batch_texts,
                    metadatas=batch_metadatas,
                    ids=batch_ids
                )
                
                print(f"âœ… æ‰¹æ¬¡ {i+1}/{batches} å¤„ç†å®Œæˆ")
            
            print(f"\nğŸ‰ æˆåŠŸå°† {len(texts)} æ¡FAQæ•°æ®å­˜å‚¨åˆ°ChromaDB")
            
            # åˆ·æ–°æœç´¢æç¤ºåˆ—è¡¨
            try:
                from app.services.hint_service import hint_service
                hint_service.refresh()
                print("âœ… æœç´¢æç¤ºåˆ—è¡¨å·²åˆ·æ–°")
            except Exception as e:
                print(f"âš ï¸ åˆ·æ–°æœç´¢æç¤ºåˆ—è¡¨å¤±è´¥: {str(e)}")
            
            return True
            
        except Exception as e:
            print(f"âŒ å­˜å‚¨FAQæ•°æ®åˆ°ChromaDBå¤±è´¥: {str(e)}")
            import traceback
            traceback.print_exc()
            return False

    def preprocess_faq_text(self, text):
        """
        é¢„å¤„ç†FAQæ–‡æœ¬  ä¸­é—´å‡½æ•°ï¼Œè¢«store_faq_in_chromadbè°ƒç”¨
        
        Args:
            text (str): åŸå§‹æ–‡æœ¬
            
        Returns:
            list: å¤„ç†åçš„æ–‡æœ¬åˆ—è¡¨
        """
        # æ£€æŸ¥æ˜¯å¦ä¸ºNoneæˆ–ç©ºå­—ç¬¦ä¸²
        if text is None or not text.strip():
            return []
            
        # ç§»é™¤å¸¸è§çš„å¯¹è¯è¯è¯­
        stop_words = ["æ‚¨å¥½", "è¯·é—®", "ä½ å¥½", "è¯·", "æ€ä¹ˆ", "å¦‚ä½•", "åœ¨å“ª", "å“ªé‡Œ", "æ˜¯å¦", "èƒ½å¦"]
        
        # æŒ‰æ¢è¡Œç¬¦åˆ†å‰²å¤šä¸ªé—®é¢˜
        questions = text.split('\n')
        
        processed_questions = []
        for question in questions:
            # ç§»é™¤åœç”¨è¯
            for word in stop_words:
                question = question.replace(word, "")
            # ç§»é™¤å¤šä½™ç©ºæ ¼
            question = " ".join(question.split())
            if question:  # å¦‚æœå¤„ç†åçš„é—®é¢˜ä¸ä¸ºç©º
                processed_questions.append(question)
        
        return processed_questions

    def calculate_keyword_similarity(self, query, keywords):
        """
        è®¡ç®—å…³é”®è¯ç›¸ä¼¼åº¦  ä¸­é—´å‡½æ•°ï¼Œè¢«search_similar_faqsè°ƒç”¨
        
        Args:
            query (str): æŸ¥è¯¢æ–‡æœ¬
            keywords (str): å…³é”®è¯å­—ç¬¦ä¸²
            
        Returns:
            float: ç›¸ä¼¼åº¦åˆ†æ•° (0-1)
        """
        if not keywords:
            return 0.0
            
        # å°†å…³é”®è¯å­—ç¬¦ä¸²åˆ†å‰²æˆåˆ—è¡¨
        keyword_list = keywords.split()
        
        # è®¡ç®—æŸ¥è¯¢ä¸­åŒ…å«å¤šå°‘ä¸ªå…³é”®è¯
        matches = sum(1 for keyword in keyword_list if keyword in query)
        
        # è¿”å›åŒ¹é…æ¯”ä¾‹
        return matches / len(keyword_list) if keyword_list else 0.0

    def search_similar_faqs(self, query, n_results=3):
        """
        æœç´¢ä¸æŸ¥è¯¢ç›¸ä¼¼çš„é—®é¢˜  ä¸­é—´å‡½æ•°ï¼Œè¢«get_similar_faq_idsè°ƒç”¨
        
        Args:
            query (str): æŸ¥è¯¢æ–‡æœ¬
            n_results (int): è¿”å›ç»“æœæ•°é‡
            
        Returns:
            list: ç›¸ä¼¼é—®é¢˜åˆ—è¡¨
        """
        try:
            print(f"\nå¼€å§‹æœç´¢: {query}")
            
            # å®šä¹‰æ­£ç¡®çš„é›†åˆåç§°
            collection_name = "im-customer-service"
            
            # æ£€æŸ¥é›†åˆæ˜¯å¦å­˜åœ¨
            collections = self.chroma_client.list_collections()
            print(f"å½“å‰å¯ç”¨çš„é›†åˆ: {[c.name for c in collections]}")
            
            # æ£€æŸ¥é›†åˆåç§°æ˜¯å¦åœ¨å¯ç”¨é›†åˆåˆ—è¡¨ä¸­
            if not any(c.name == collection_name for c in collections):
                print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°åä¸º '{collection_name}' çš„é›†åˆ")
                print("è¯·ç¡®ä¿å·²ç»è¿è¡Œè¿‡ store_faq_in_chromadb() æ¥åˆå§‹åŒ–æ•°æ®")
                return []
            
            try:
                # è·å–é›†åˆ
                collection = self.chroma_client.get_collection(collection_name)
                print(f"âœ… æˆåŠŸè·å– {collection_name} é›†åˆ")
            except Exception as e:
                print(f"âŒ è·å–é›†åˆå¤±è´¥: {str(e)}")
                print("è¯·ç¡®ä¿å·²ç»è¿è¡Œè¿‡ store_faq_in_chromadb() æ¥åˆå§‹åŒ–æ•°æ®")
                return []
            
            # æ£€æŸ¥é›†åˆæ˜¯å¦ä¸ºç©º
            collection_count = collection.count()
            if collection_count == 0:
                print("âš ï¸ è­¦å‘Š: é›†åˆä¸ºç©ºï¼Œæ²¡æœ‰å¯æœç´¢çš„æ•°æ®")
                return []
            
            print(f"é›†åˆä¸­åŒ…å« {collection_count} æ¡æ•°æ®")
            
            # é¢„å¤„ç†æŸ¥è¯¢æ–‡æœ¬
            processed_queries = self.preprocess_faq_text(query)
            if not processed_queries:
                print("âš ï¸ è­¦å‘Š: æŸ¥è¯¢æ–‡æœ¬é¢„å¤„ç†åä¸ºç©º")
                return []
                
            processed_query = processed_queries[0]  # é˜²æ­¢ç´¢å¼•è¶Šç•Œ
            print(f"å¤„ç†åçš„æŸ¥è¯¢: {processed_query}")
            
            # è·å–æŸ¥è¯¢æ–‡æœ¬çš„ embedding
            print("è·å–æŸ¥è¯¢æ–‡æœ¬çš„ embedding...")
            query_embedding = self.get_embedding(processed_query)
            if not query_embedding:
                print("âŒ é”™è¯¯: æ— æ³•è·å–æŸ¥è¯¢æ–‡æœ¬çš„ embedding")
                return []
            
            # æœç´¢ç›¸ä¼¼é—®é¢˜ï¼Œè·å–æ›´å¤šç»“æœç”¨äºé‡æ–°æ’åº
            print("åœ¨ ChromaDB ä¸­æœç´¢ç›¸ä¼¼é—®é¢˜...")
            results = collection.query(
                query_embeddings=[query_embedding],
                n_results=min(n_results * 2, collection_count)  # ç¡®ä¿ä¸è¶…è¿‡é›†åˆä¸­çš„æ•°æ®æ•°é‡
            )
            
            # æ£€æŸ¥ç»“æœæ˜¯å¦ä¸ºç©º
            if not results or 'documents' not in results or not results['documents'] or len(results['documents'][0]) == 0:
                print("âš ï¸ è­¦å‘Š: æœªæ‰¾åˆ°ä»»ä½•ç›¸ä¼¼é—®é¢˜")
                return []
                
            # ç»“åˆå‘é‡ç›¸ä¼¼åº¦å’Œå…³é”®è¯åŒ¹é…é‡æ–°æ’åº
            similar_faqs = []
            for i in range(len(results['documents'][0])):
                try:
                    # è·å–åŸå§‹FAQæ–‡æœ¬
                    faq_text = results['documents'][0][i]
                    
                    # æ£€æŸ¥å…ƒæ•°æ®æ˜¯å¦å­˜åœ¨
                    if 'metadatas' not in results or not results['metadatas'] or len(results['metadatas'][0]) <= i:
                        print(f"âš ï¸ è­¦å‘Š: ç´¢å¼• {i} çš„å…ƒæ•°æ®ä¸å­˜åœ¨")
                        continue
                        
                    # æ£€æŸ¥è·ç¦»æ˜¯å¦å­˜åœ¨
                    if 'distances' not in results or not results['distances'] or len(results['distances'][0]) <= i:
                        print(f"âš ï¸ è­¦å‘Š: ç´¢å¼• {i} çš„è·ç¦»ä¸å­˜åœ¨")
                        continue
                    
                    # é¢„å¤„ç†FAQæ–‡æœ¬
                    processed_faqs = self.preprocess_faq_text(faq_text)
                    if not processed_faqs:
                        processed_faqs = [faq_text]  # å¦‚æœé¢„å¤„ç†åä¸ºç©ºï¼Œä½¿ç”¨åŸå§‹æ–‡æœ¬
                    
                    # è®¡ç®—æœ€ä½³åŒ¹é…çš„FAQæ–‡æœ¬çš„ç›¸ä¼¼åº¦
                    best_semantic_score = results['distances'][0][i]  # è¾ƒå°çš„è·ç¦»è¡¨ç¤ºæ›´ç›¸ä¼¼
                    
                    # æ£€æŸ¥å…³é”®è¯å­—æ®µæ˜¯å¦å­˜åœ¨
                    keywords = results['metadatas'][0][i].get('keywords', '')
                    
                    # è®¡ç®—å…³é”®è¯åŒ¹é…åˆ†æ•°
                    keyword_score = self.calculate_keyword_similarity(
                        processed_query,
                        keywords
                    )
                    
                    # æ£€æŸ¥IDå­—æ®µæ˜¯å¦å­˜åœ¨
                    if 'id' not in results['metadatas'][0][i]:
                        print(f"âš ï¸ è­¦å‘Š: ç´¢å¼• {i} çš„å…ƒæ•°æ®ä¸­æ²¡æœ‰IDå­—æ®µ")
                        continue
                    
                    # ç»¼åˆå¾—åˆ† (å°†è·ç¦»è½¬æ¢ä¸ºç›¸ä¼¼åº¦åˆ†æ•°ï¼Œå¹¶ä¸å…³é”®è¯å¾—åˆ†ç»“åˆ)
                    combined_score = (1 - best_semantic_score) * 0.7 + keyword_score * 0.3
                    
                    similar_faqs.append({
                        'id': results['metadatas'][0][i]['id'],
                        'faq': faq_text,
                        'keywords': keywords,
                        'distance': best_semantic_score,
                        'keyword_score': keyword_score,
                        'combined_score': combined_score
                    })
                except Exception as e:
                    print(f"âŒ å¤„ç†ç´¢å¼• {i} çš„ç»“æœæ—¶å‡ºé”™: {str(e)}")
                    continue
            
            # æ£€æŸ¥æ˜¯å¦æœ‰æœ‰æ•ˆç»“æœ
            if not similar_faqs:
                print("âš ï¸ è­¦å‘Š: å¤„ç†åæ²¡æœ‰æœ‰æ•ˆçš„ç›¸ä¼¼é—®é¢˜")
                return []
                
            # æ ¹æ®ç»¼åˆå¾—åˆ†é‡æ–°æ’åº
            similar_faqs.sort(key=lambda x: x['combined_score'], reverse=True)
            
            # åªè¿”å›è¯·æ±‚çš„æ•°é‡
            similar_faqs = similar_faqs[:n_results]
            
            print(f"âœ… æ‰¾åˆ° {len(similar_faqs)} ä¸ªç›¸ä¼¼é—®é¢˜")
            return similar_faqs
            
        except Exception as e:
            print(f"âŒ æœç´¢ç›¸ä¼¼é—®é¢˜å¤±è´¥: {str(e)}")
            import traceback
            traceback.print_exc()  # æ‰“å°å®Œæ•´çš„å †æ ˆè·Ÿè¸ª
            print("è¯·æ£€æŸ¥:")
            print("1. ChromaDB æœåŠ¡æ˜¯å¦æ­£å¸¸è¿è¡Œ")
            print("2. æ•°æ®åº“æ–‡ä»¶æƒé™æ˜¯å¦æ­£ç¡®")
            print("3. æ˜¯å¦å·²ç»æˆåŠŸå¯¼å…¥æ•°æ®")
            return []

    def get_similar_faq_ids(self, query, n_results=3):
        """
        è·å–ä¸æŸ¥è¯¢ç›¸ä¼¼çš„é—®é¢˜IDåˆ—è¡¨ï¼ŒæŒ‰ç»¼åˆå¾—åˆ†ä»é«˜åˆ°ä½æ’åº  ä¸­é—´å‡½æ•°ï¼Œè¢«get_faq_details_by_idsè°ƒç”¨
        
        Args:
            query (str): æŸ¥è¯¢æ–‡æœ¬
            n_results (int): è¿”å›ç»“æœæ•°é‡
            
        Returns:
            list: ç›¸ä¼¼é—®é¢˜IDåˆ—è¡¨
        """
        try:
            # è·å–ç›¸ä¼¼é—®é¢˜
            similar_faqs = self.search_similar_faqs(query, n_results)
            
            # æå–IDå¹¶æŒ‰ç»¼åˆå¾—åˆ†æ’åº
            faq_ids = [faq['id'] for faq in similar_faqs]
            
            print(f"\næå–åˆ° {len(faq_ids)} ä¸ªç›¸ä¼¼é—®é¢˜ID:")
            for i, faq_id in enumerate(faq_ids, 1):
                print(f"{i}. ID: {faq_id}")
            return faq_ids
            
        except Exception as e:
            print(f"âŒ æå–ç›¸ä¼¼é—®é¢˜IDå¤±è´¥: {str(e)}")
            return []

    def get_faq_details_by_ids(self, faq_ids):
        """
        æ ¹æ®FAQ IDåˆ—è¡¨è·å–å®Œæ•´çš„çŸ¥è¯†åº“æ•°æ®  ä¸­é—´å‡½æ•°ï¼Œè¢«format_faq_for_ragè°ƒç”¨
        
        Args:
            faq_ids (list): FAQ IDåˆ—è¡¨
            
        Returns:
            list: åŒ…å«å®Œæ•´FAQæ•°æ®çš„åˆ—è¡¨
        """
        try:
            print(f"\nğŸ” å¼€å§‹è·å–FAQè¯¦ç»†ä¿¡æ¯...")
            
            # æ„å»ºçŸ¥è¯†åº“JSONæ–‡ä»¶è·¯å¾„
            json_path = os.path.join(self.data_dir, "strapi_knowledge_parsed.json")
            
            # æ£€æŸ¥è§£æåçš„æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not os.path.exists(json_path):
                print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°çŸ¥è¯†åº“æ–‡ä»¶ {json_path}")
                return []
            
            # è¯»å–çŸ¥è¯†åº“æ•°æ®
            with open(json_path, 'r', encoding='utf-8') as f:
                knowledge_items = json.load(f)
            
            # ç”±äºç°åœ¨strapi_knowledge_parsed.jsonç›´æ¥æ˜¯æ•°ç»„æ ¼å¼ï¼Œä¸éœ€è¦æ£€æŸ¥æ ¼å¼
            if not isinstance(knowledge_items, list):
                print("âŒ é”™è¯¯: çŸ¥è¯†åº“æ•°æ®æ ¼å¼ä¸æ­£ç¡®ï¼Œåº”ä¸ºæ•°ç»„æ ¼å¼")
                return []
            
            print(f"âœ… æˆåŠŸåŠ è½½ {len(knowledge_items)} æ¡çŸ¥è¯†åº“æ•°æ®")
            
            # åˆ›å»ºIDåˆ°æ•°æ®çš„æ˜ å°„
            id_to_data = {}
            for item in knowledge_items:
                if isinstance(item, dict) and 'id' in item:
                    item_id = str(item['id'])
                    id_to_data[item_id] = item
            
            # è·å–æŒ‡å®šIDçš„æ•°æ®
            faq_details = []
            for faq_id in faq_ids:
                faq_id_str = str(faq_id)
                if faq_id_str in id_to_data:
                    faq_details.append(id_to_data[faq_id_str])
                else:
                    print(f"âš ï¸ è­¦å‘Š: æœªæ‰¾åˆ°IDä¸º {faq_id} çš„FAQæ•°æ®")
            
            # æ‰“å°ç»“æœ
            print(f"\nâœ… æˆåŠŸè·å– {len(faq_details)} æ¡FAQè¯¦ç»†ä¿¡æ¯:")
            for i, faq in enumerate(faq_details, 1):
                print(f"\n{i}. ID: {faq.get('id')}")
                print(f"   FAQ: {faq.get('FAQ', '')[:50]}...")
                print(f"   Response: {faq.get('Response', '')[:50]}...")
                print(f"   Keywords: {faq.get('Keywords', '')}")
                print(f"   ç§»åŠ¨ç«¯å›¾ç‰‡: {'âœ…' if faq.get('Response_Pic_App_URL') else 'âŒ'}")
                print(f"   PCç«¯å›¾ç‰‡: {'âœ…' if faq.get('Response_Pic_Pc_URL') else 'âŒ'}")
            
            return faq_details
                
        except Exception as e:
            print(f"âŒ è·å–FAQè¯¦ç»†ä¿¡æ¯å¤±è´¥: {str(e)}")
            import traceback
            traceback.print_exc()  # æ‰“å°è¯¦ç»†çš„å †æ ˆè·Ÿè¸ª
            return []

    def format_faq_for_rag(self, faq_details, query=None):
        """
        å°†FAQè¯¦ç»†ä¿¡æ¯æ ¼å¼åŒ–ä¸ºé€‚åˆRAGçš„æ–‡æœ¬æ ¼å¼
        
        Args:
            faq_details (list): FAQè¯¦ç»†ä¿¡æ¯åˆ—è¡¨
            query (str, optional): ç”¨æˆ·æŸ¥è¯¢
            
        Returns:
            str: æ ¼å¼åŒ–åçš„æ–‡æœ¬
        """
        try:
            print("\nğŸ“ å¼€å§‹æ ¼å¼åŒ–FAQä¿¡æ¯ä¸ºRAGæ–‡æœ¬...")
            
            # æ„å»ºæ–‡æœ¬
            formatted_text = []
            
            # æ·»åŠ è¯­æ–™åº“çŸ¥è¯†
            formatted_text.append("ã€è¯­æ–™åº“çŸ¥è¯†ã€‘")
            for i, faq in enumerate(faq_details, 1):
                # æå–å…³é”®å­—æ®µï¼Œç›´æ¥ä»é¡¶çº§å¯¹è±¡è·å–
                question = faq.get('FAQ', '')
                response = faq.get('Response', '')
                keywords = faq.get('Keywords', '')
                
                # ç›´æ¥ä»è§£æåçš„æ•°æ®ä¸­è·å–å›¾ç‰‡URL
                app_image_url = faq.get('Response_Pic_App_URL', '')
                pc_image_url = faq.get('Response_Pic_Pc_URL', '')
                
                # æ‰“å°å‡ºæ‰€æœ‰è·å–åˆ°çš„å­—æ®µä»¥ä¾¿è°ƒè¯•
                print(f"\nFAQ {i} å­—æ®µ:")
                print(f"é—®é¢˜: {question}")
                print(f"å›ç­”: {response}")
                print(f"å…³é”®è¯: {keywords}")
                print(f"APPå›¾ç‰‡: {app_image_url}")
                print(f"PCå›¾ç‰‡: {pc_image_url}")
                
                # æ ¼å¼åŒ–æ¯ä¸ªFAQæ¡ç›®
                faq_text = f"FAQ {i}:\n"
                faq_text += f"é—®é¢˜: {question}\n"
                faq_text += f"å›ç­”: {response}\n"
                if keywords:
                    faq_text += f"å…³é”®è¯: {keywords}\n"
                
                # æ·»åŠ å›¾ç‰‡URLï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                if app_image_url:
                    faq_text += f"APPç«¯å›¾ç‰‡: {app_image_url}\n"
                if pc_image_url:
                    faq_text += f"PCç«¯å›¾ç‰‡: {pc_image_url}\n"
                
                faq_text += "-" * 50  # åˆ†éš”çº¿
                
                formatted_text.append(faq_text)
                   
            # åˆå¹¶æ‰€æœ‰æ–‡æœ¬
            result = "\n".join(formatted_text)
            
            print("âœ… FAQä¿¡æ¯æ ¼å¼åŒ–å®Œæˆ")
            return result
            
        except Exception as e:
            print(f"âŒ æ ¼å¼åŒ–FAQä¿¡æ¯å¤±è´¥: {str(e)}")
            import traceback
            traceback.print_exc()  # æ‰“å°è¯¦ç»†çš„å †æ ˆè·Ÿè¸ª
            return ""
    
    def _extract_large_image_url(self, pic_data):
        """
        ä»å›¾ç‰‡æ•°æ®ä¸­æå–å¤§å›¾URL  ä¸­é—´å‡½æ•°ï¼Œè¢«format_faq_for_ragè°ƒç”¨
        
        Args:
            pic_data (dict): å›¾ç‰‡æ•°æ®å­—å…¸
            
        Returns:
            str: å¤§å›¾URLï¼Œå¦‚æœä¸å­˜åœ¨åˆ™è¿”å›ç©ºå­—ç¬¦ä¸²
        """
        try:
            # æ£€æŸ¥pic_dataæ˜¯å¦åŒ…å«å¿…è¦çš„ç»“æ„
            if not pic_data or 'data' not in pic_data or not pic_data['data']:
                return ""
                
            # è·å–å›¾ç‰‡å±æ€§
            attributes = pic_data['data'].get('attributes', {})
            
            # è·å–formats
            formats = attributes.get('formats', {})
            
            # å°è¯•è·å–å¤§å›¾URL
            if 'large' in formats and 'url' in formats['large']:
                return formats['large']['url']
            
            # å¦‚æœæ²¡æœ‰largeæ ¼å¼ï¼Œå°è¯•è·å–å…¶ä»–æ ¼å¼
            for format_type in ['medium', 'small', 'thumbnail']:
                if format_type in formats and 'url' in formats[format_type]:
                    return formats[format_type]['url']
            
            # å¦‚æœformatsä¸­æ²¡æœ‰ä»»ä½•æ ¼å¼ï¼Œå°è¯•ä»åŸå§‹å›¾ç‰‡è·å–URL
            if 'url' in attributes:
                return attributes['url']
                
            return ""
        except Exception as e:
            print(f"âš ï¸ æå–å›¾ç‰‡URLå¤±è´¥: {str(e)}")
            return ""

    def inspect_chromadb(self):
        """
        æ£€æŸ¥ ChromaDB çš„æ•°æ®å­˜å‚¨æƒ…å†µ  è¢«main.pyè°ƒç”¨
        
        Returns:
            dict: åŒ…å« ChromaDB çŠ¶æ€ä¿¡æ¯çš„å­—å…¸
        """
        try:
            print("\nğŸ” å¼€å§‹æ£€æŸ¥ ChromaDB çŠ¶æ€...")
            
            # æ£€æŸ¥æ•°æ®ç›®å½•
            db_path = os.path.join(self.data_dir, "chroma_db")
            db_size = 0
            if os.path.exists(db_path):
                for root, dirs, files in os.walk(db_path):
                    for file in files:
                        file_path = os.path.join(root, file)
                        db_size += os.path.getsize(file_path)
            
            # è½¬æ¢æ•°æ®åº“å¤§å°ä¸ºå¯è¯»æ ¼å¼
            size_str = f"{db_size / (1024*1024):.2f} MB" if db_size > 1024*1024 else f"{db_size / 1024:.2f} KB"
            
            # è·å–æ‰€æœ‰é›†åˆ
            collections = self.chroma_client.list_collections()
            print(f"\nğŸ“š å½“å‰å¯ç”¨çš„é›†åˆ: {[c.name for c in collections]}")
            
            if not collections:
                print("âš ï¸ è­¦å‘Š: æ²¡æœ‰æ‰¾åˆ°ä»»ä½•é›†åˆ")
                return {
                    "status": "empty",
                    "collections": [],
                    "db_path": db_path,
                    "db_size": db_size,
                    "db_size_readable": size_str
                }
            
            # æ”¶é›†æ¯ä¸ªé›†åˆçš„ä¿¡æ¯
            collections_info = []
            for collection in collections:
                try:
                    # è·å–é›†åˆä¸­çš„æ•°æ®æ¡æ•°
                    count = collection.count()
                    
                    # è·å–é›†åˆçš„å…ƒæ•°æ®
                    metadata = collection.metadata
                    
                    # è·å–é›†åˆçš„ç»´åº¦ï¼ˆå¦‚æœå¯ç”¨ï¼‰
                    dimension = None
                    try:
                        # å°è¯•è·å–ä¸€æ¡æ•°æ®æ¥æŸ¥çœ‹ç»´åº¦
                        peek = collection.peek()
                        if peek and 'embeddings' in peek and len(peek['embeddings']) > 0:
                            dimension = len(peek['embeddings'][0])
                    except:
                        pass
                    
                    collection_info = {
                        "name": collection.name,
                        "count": count,
                        "dimension": dimension,
                        "metadata": metadata
                    }
                    collections_info.append(collection_info)
                    
                    # æ‰“å°é›†åˆä¿¡æ¯
                    print(f"\nğŸ“Š é›†åˆ '{collection.name}' ä¿¡æ¯:")
                    print(f"- æ•°æ®æ¡æ•°: {count}")
                    if dimension:
                        print(f"- å‘é‡ç»´åº¦: {dimension}")
                    print(f"- å…ƒæ•°æ®: {metadata}")
                    
                except Exception as e:
                    print(f"âŒ è·å–é›†åˆ '{collection.name}' ä¿¡æ¯å¤±è´¥: {str(e)}")
                    collections_info.append({
                        "name": collection.name,
                        "error": str(e)
                    })
            
            print(f"\nğŸ’¾ æ•°æ®åº“å­˜å‚¨ä¿¡æ¯:")
            print(f"- å­˜å‚¨è·¯å¾„: {db_path}")
            print(f"- æ€»å¤§å°: {size_str}")
            
            return {
                "status": "success",
                "collections": collections_info,
                "db_path": db_path,
                "db_size": db_size,
                "db_size_readable": size_str
            }
            
        except Exception as e:
            print(f"\nâŒ æ£€æŸ¥ ChromaDB çŠ¶æ€å¤±è´¥: {str(e)}")
            return {
                "status": "error",
                "error": str(e),
                "collections": [],
                "db_path": os.path.join(self.data_dir, "chroma_db"),
                "db_size": 0,
                "db_size_readable": "0 KB"
            }
            
    def update_knowledge_with_responses(self):
        """
        æ›´æ–°çŸ¥è¯†åº“æ–‡ä»¶ï¼Œä¸ºæ‰€æœ‰æ¡ç›®æ·»åŠ ç©ºçš„Responseå­—æ®µ
        
        Returns:
            bool: æ“ä½œæ˜¯å¦æˆåŠŸ
        """
        try:
            print("\nğŸ”§ å¼€å§‹æ›´æ–°çŸ¥è¯†åº“æ–‡ä»¶ï¼Œæ·»åŠ Responseå­—æ®µ...")
            
            # æ„å»ºçŸ¥è¯†åº“æ–‡ä»¶è·¯å¾„
            json_path = os.path.join(self.data_dir, "strapi_knowledge_parsed.json")
            if not os.path.exists(json_path):
                print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°çŸ¥è¯†åº“æ–‡ä»¶ {json_path}")
                return False
                
            # è¯»å–ç°æœ‰çŸ¥è¯†åº“æ•°æ®
            with open(json_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
                
            print(f"âœ… æˆåŠŸè¯»å– {len(data)} æ¡æ•°æ®")
            
            # ä¸ºæ¯æ¡æ•°æ®æ·»åŠ Responseå­—æ®µï¼ˆå¦‚æœå°šä¸å­˜åœ¨ï¼‰
            updated_count = 0
            for item in data:
                if 'Response' not in item:
                    item['Response'] = ""  # æ·»åŠ ç©ºçš„Responseå­—æ®µ
                    updated_count += 1
            
            # ä¿å­˜æ›´æ–°åçš„æ•°æ®
            with open(json_path, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
                
            print(f"âœ… æˆåŠŸæ›´æ–°çŸ¥è¯†åº“æ–‡ä»¶")
            print(f"- æ€»æ¡ç›®æ•°: {len(data)}")
            print(f"- æ›´æ–°æ¡ç›®æ•°: {updated_count}")
            
            return True
            
        except Exception as e:
            print(f"âŒ æ›´æ–°çŸ¥è¯†åº“æ–‡ä»¶å¤±è´¥: {str(e)}")
            import traceback
            traceback.print_exc()  # æ‰“å°è¯¦ç»†çš„å †æ ˆè·Ÿè¸ª
            return False

    def get_recently_updated_knowledge(self, endpoint="api/im-customer-service-knowledge-bases", hours=1, params=None):
        """
        è·å–æœ€è¿‘æ›´æ–°çš„çŸ¥è¯†ç‚¹æ•°æ®ï¼ˆå¢é‡æ›´æ–°ï¼‰
        
        Args:
            endpoint (str): API ç«¯ç‚¹
            hours (int): è·å–å¤šå°‘å°æ—¶å†…æ›´æ–°çš„æ•°æ®
            params (dict, optional): è¯·æ±‚å‚æ•°
            
        Returns:
            list: æœ€è¿‘æ›´æ–°çš„æ•°æ®
        """
        if params is None:
            params = {}
            
        # è®¡ç®—æŸ¥è¯¢æ—¶é—´èŒƒå›´
        now = datetime.now()
        update_after = now - timedelta(hours=hours)
        update_after_str = update_after.strftime("%Y-%m-%dT%H:%M:%S.000Z")
        
        # æ·»åŠ æ—¶é—´è¿‡æ»¤å™¨å’Œ populate å‚æ•°
        filter_params = {
            'populate': '*',
            'filters[updatedAt][$gt]': update_after_str
        }
        
        # åˆå¹¶å‚æ•°
        query_params = {**params, **filter_params}
        
        # è·å–æ»¡è¶³æ¡ä»¶çš„æ•°æ®
        recent_data = self.get_all_knowledge(endpoint, query_params)
        
        if recent_data:
            print(f"âœ… å‘ç° {len(recent_data)} æ¡æœ€è¿‘ {hours} å°æ—¶å†…æ›´æ–°çš„æ•°æ®")
        else:
            print(f"â„¹ï¸ æ²¡æœ‰å‘ç°æœ€è¿‘ {hours} å°æ—¶å†…æ›´æ–°çš„æ•°æ®")
            
        return recent_data
    
    def fetch_and_save_updated_knowledge(self, endpoint="api/im-customer-service-knowledge-bases", hours=1, params=None):
        """
        è·å–å¹¶ä¿å­˜æœ€è¿‘æ›´æ–°çš„çŸ¥è¯†ç‚¹æ•°æ®
        
        Args:
            endpoint (str): API ç«¯ç‚¹
            hours (int): è·å–å¤šå°‘å°æ—¶å†…æ›´æ–°çš„æ•°æ®
            params (dict, optional): é¢å¤–çš„è¯·æ±‚å‚æ•°
            
        Returns:
            tuple: (æœ‰æ›´æ–°, æ–‡ä»¶è·¯å¾„) - æ˜¯å¦æœ‰æ›´æ–°çš„æ•°æ®å’Œä¿å­˜çš„æ–‡ä»¶è·¯å¾„
        """
        if params is None:
            params = {}
            
        # è·å–æœ€è¿‘æ›´æ–°çš„æ•°æ®
        recent_data = self.get_recently_updated_knowledge(endpoint, hours, params)
        
        if not recent_data:
            # æ²¡æœ‰æ›´æ–°çš„æ•°æ®ï¼Œç›´æ¥è¿”å›
            return False, None
            
        # æ„å»ºå®Œæ•´æ•°æ®ç»“æ„
        update_data = {
            "data": recent_data,
            "meta": {
                "pagination": {
                    "page": 1,
                    "pageSize": len(recent_data),
                    "pageCount": 1,
                    "total": len(recent_data)
                }
            }
        }
        
        # ä¿å­˜ä¸º JSON æ–‡ä»¶ - ä½¿ç”¨æ—¶é—´æˆ³é¿å…æ–‡ä»¶åå†²çª
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_file = f"{endpoint.replace('/', '_')}_update_{timestamp}.json"
        filepath = self.save_to_json(update_data, output_file)
        
        print(f"âœ… æ–°å¢/æ›´æ–°çš„æ•°æ®å·²ä¿å­˜åˆ°: {filepath}")
        return True, filepath
    
    def update_chromadb_with_new_data(self, input_file, recreate_collection=False):
        """
        ä½¿ç”¨æ–°å¢/æ›´æ–°çš„æ•°æ®æ›´æ–°ChromaDB
        
        Args:
            input_file (str): è¾“å…¥çš„æ›´æ–°æ•°æ®JSONæ–‡ä»¶è·¯å¾„
            recreate_collection (bool): æ˜¯å¦é‡æ–°åˆ›å»ºé›†åˆ
            
        Returns:
            bool: æ˜¯å¦æˆåŠŸæ›´æ–°
        """
        try:
            if recreate_collection:
                # å¦‚æœé€‰æ‹©é‡å»ºé›†åˆï¼Œç›´æ¥ä½¿ç”¨ç°æœ‰çš„å…¨é‡æ›´æ–°æ–¹æ³•
                return self.store_faq_in_chromadb(recreate_collection=True)

            # ä»JSONæ–‡ä»¶è¯»å–æ›´æ–°æ•°æ®
            input_path = input_file if os.path.isabs(input_file) else os.path.join(self.data_dir, input_file)

            with open(input_path, 'r', encoding='utf-8') as f:
                update_data = json.load(f)

            # è§£ææ•°æ® - ä¿®æ”¹ä¸ºå¤„ç† FAQ/Response ç»“æ„
            faqs_to_update = []
            if 'data' in update_data and isinstance(update_data['data'], list):
                for item in update_data['data']:
                    item_id = str(item.get('id', ''))
                    if not item_id:
                        print(f"âš ï¸ è·³è¿‡æ²¡æœ‰IDçš„æ›´æ–°è®°å½•")
                        continue

                    if 'attributes' in item:
                        faq = item['attributes'].get('FAQ', '')
                        keywords = item['attributes'].get('Keywords', '')
                        response = item['attributes'].get('Response', '')

                        # è‡³å°‘éœ€è¦ FAQ å†…å®¹æ‰èƒ½æ›´æ–°å‘é‡åº“
                        if faq:
                            # ä½¿ç”¨ä¸ store_faq_in_chromadb ç±»ä¼¼çš„é¢„å¤„ç†å’Œæ–‡æ¡£æ„å»º
                            faq_text_list = self.preprocess_faq_text(faq)
                            if not faq_text_list:
                                print(f"âš ï¸ è­¦å‘Š: IDä¸º {item_id} çš„æ›´æ–°FAQå¤„ç†åä¸ºç©ºï¼Œè·³è¿‡")
                                continue
                            faq_text = "\n".join(faq_text_list)

                            metadata = {
                                "id": item_id,
                                "faq": faq if faq is not None else "",
                                "keywords": keywords if keywords is not None else "",
                                "response": response if response is not None else ""
                            }

                            faqs_to_update.append({
                                'id': f"faq_{item_id}", # ä½¿ç”¨ä¸ store_faq_in_chromadb ä¸€è‡´çš„IDæ ¼å¼
                                'document': faq_text,
                                'metadata': metadata
                            })
                        else:
                             print(f"âš ï¸ è­¦å‘Š: IDä¸º {item_id} çš„æ›´æ–°è®°å½•ç¼ºå°‘FAQå†…å®¹ï¼Œè·³è¿‡")

            if not faqs_to_update:
                print("æ²¡æœ‰å¯æ›´æ–°çš„FAQå†…å®¹") # ä¿®æ”¹æ—¥å¿—æ¶ˆæ¯
                return False

            print(f"è§£æå¾—åˆ° {len(faqs_to_update)} æ¡å¾…æ›´æ–°çš„FAQ")

            # è·å–æˆ–åˆ›å»ºé›†åˆ
            collection_name = "im-customer-service"
            try:
                collection = self.chroma_client.get_collection(
                    name=collection_name,
                    embedding_function=self._get_embedding_function() # ç¡®ä¿ä½¿ç”¨åµŒå…¥å‡½æ•°
                )
                print(f"è·å–åˆ°å·²å­˜åœ¨çš„é›†åˆ: {collection_name}")
            except Exception as e:
                print(f"è·å–é›†åˆæ—¶å‡ºé”™ï¼Œå°è¯•åˆ›å»º: {str(e)}")
                collection = self.chroma_client.create_collection(
                    name=collection_name,
                    embedding_function=self._get_embedding_function()
                )
                print(f"åˆ›å»ºæ–°é›†åˆ: {collection_name}")

            # åµŒå…¥å¹¶æ›´æ–°æ•°æ®
            successful_updates = 0
            ids_to_upsert = [faq['id'] for faq in faqs_to_update]
            documents_to_upsert = [faq['document'] for faq in faqs_to_update]
            metadatas_to_upsert = [faq['metadata'] for faq in faqs_to_update]

            # ä½¿ç”¨ upsert è¿›è¡Œæ›´æ–°æˆ–æ·»åŠ 
            try:
                collection.upsert(
                    ids=ids_to_upsert,
                    documents=documents_to_upsert,
                    metadatas=metadatas_to_upsert
                )
                successful_updates = len(faqs_to_update)
                print(f"âœ… æˆåŠŸæ›´æ–°/æ·»åŠ  {successful_updates} æ¡FAQåˆ° ChromaDB")
            except Exception as e:
                print(f"âŒ æ›´æ–°/æ·»åŠ  ChromaDB æ—¶å‡ºé”™: {str(e)}")
                # å¯ä»¥åœ¨è¿™é‡Œæ·»åŠ æ›´è¯¦ç»†çš„é”™è¯¯å¤„ç†æˆ–é‡è¯•é€»è¾‘

            return successful_updates > 0

        except Exception as e:
            print(f"âŒ æ›´æ–° ChromaDB å¤±è´¥: {str(e)}")
            import traceback
            traceback.print_exc()
            return False
    
    def incremental_update_knowledge_base(self, hours=1):
        """
        å¢é‡æ›´æ–°çŸ¥è¯†åº“
        
        Args:
            hours (int): è·å–å¤šå°‘å°æ—¶å†…æ›´æ–°çš„æ•°æ®
            
        Returns:
            bool: æ˜¯å¦æˆåŠŸæ›´æ–°
        """
        try:
            print(f"å¼€å§‹å¢é‡æ›´æ–°çŸ¥è¯†åº“ï¼ˆè·å–æœ€è¿‘ {hours} å°æ—¶çš„æ›´æ–°ï¼‰...")
            
            # 1. è·å–æœ€è¿‘æ›´æ–°çš„æ•°æ®
            has_updates, update_file = self.fetch_and_save_updated_knowledge(  #è¿”å›æ–°å­˜çš„jsonæ–‡ä»¶è·¯å¾„
                endpoint="api/im-customer-service-knowledge-bases", 
                hours=hours
            )
            
            if not has_updates:
                print("æ²¡æœ‰æ–°çš„æ›´æ–°æ•°æ®ï¼Œæ— éœ€æ›´æ–°å‘é‡æ•°æ®åº“")
                return False
                
            # 2. æ›´æ–°å‘é‡æ•°æ®åº“
            updated = self.update_chromadb_with_new_data(update_file)
            
            if updated:
                print("âœ… çŸ¥è¯†åº“å¢é‡æ›´æ–°æˆåŠŸ")
                
                # 3. æ›´æ–°ä¸»çŸ¥è¯†åº“æ–‡ä»¶ (strapi_knowledge_parsed.json)
                kb_updated_success = False # Flag to track if KB file update was successful
                try:
                    # è°ƒç”¨ update_knowledge_base_file ä½¿ç”¨ä¸´æ—¶ update æ–‡ä»¶æ›´æ–°ä¸»æ–‡ä»¶
                    kb_updated = self.update_knowledge_base_file(update_file) # <--- æ›´æ–°ä¸»çŸ¥è¯†åº“æ–‡ä»¶
                    if kb_updated:
                        print("âœ… ä¸»çŸ¥è¯†åº“æ–‡ä»¶å·²æ›´æ–°")
                        kb_updated_success = True
                    else:
                        print("âš ï¸ ä¸»çŸ¥è¯†åº“æ–‡ä»¶æ›´æ–°å¤±è´¥")
                except Exception as e:
                    print(f"âš ï¸ æ›´æ–°ä¸»çŸ¥è¯†åº“æ–‡ä»¶å¤±è´¥: {str(e)}")

                # 4. å¦‚æœä¸»çŸ¥è¯†åº“æ–‡ä»¶æ›´æ–°æˆåŠŸï¼Œåˆ™é‡æ–°ç”Ÿæˆå¹¶åŠ è½½æœç´¢æç¤º
                if kb_updated_success:
                    try:
                        from app.services.hint_service import hint_service
                        # hint_service.refresh() # <--- ä¸å†è°ƒç”¨ refresh
                        if hint_service.generate_and_load_hints(): # <-- è°ƒç”¨ generate_and_load_hints
                            print(f"âœ… å·²æ ¹æ®æ›´æ–°åçš„çŸ¥è¯†åº“é‡æ–°ç”Ÿæˆå¹¶åŠ è½½äº† {len(hint_service.hint_list)} æ¡æœç´¢æç¤ºã€‚")
                        else:
                             print("âŒ é‡æ–°ç”Ÿæˆæœç´¢æç¤ºå¤±è´¥ã€‚")
                    except Exception as e:
                        print(f"âš ï¸ é‡æ–°ç”Ÿæˆæœç´¢æç¤ºåˆ—è¡¨å¤±è´¥: {str(e)}")
                else:
                    print("â„¹ï¸ ç”±äºä¸»çŸ¥è¯†åº“æ–‡ä»¶æ›´æ–°å¤±è´¥ï¼Œè·³è¿‡æœç´¢æç¤ºç”Ÿæˆæ­¥éª¤ã€‚")
            else:
                print("âŒ çŸ¥è¯†åº“å¢é‡æ›´æ–°å¤±è´¥æˆ–æ— æ›´æ–°")
            
            # 5. æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            try:
                delete_update_file(update_file, self.data_dir)
            except Exception as e:
                print(f"âš ï¸ åˆ é™¤ä¸´æ—¶æ–‡ä»¶æ—¶å‡ºé”™: {str(e)}")
            
            return updated
            
        except Exception as e:
            print(f"âŒ å¢é‡æ›´æ–°çŸ¥è¯†åº“å¤±è´¥: {str(e)}")
            return False

    def update_knowledge_base_file(self, new_data_file):
        """
        ä½¿ç”¨å¢é‡æ›´æ–°æ•°æ®æ›´æ–°ä¸»çŸ¥è¯†åº“æ–‡ä»¶
        
        Args:
            new_data_file (str): æ–°å¢æ•°æ®æ–‡ä»¶è·¯å¾„
            
        Returns:
            bool: æ˜¯å¦æˆåŠŸæ›´æ–°
        """
        try:
            print(f"ğŸ”„ å¼€å§‹æ›´æ–°ä¸»çŸ¥è¯†åº“æ–‡ä»¶...")
            
            # ä¸»çŸ¥è¯†åº“æ–‡ä»¶è·¯å¾„
            main_knowledge_file = os.path.join(self.data_dir, "strapi_knowledge_parsed.json")
            
            # æ£€æŸ¥ä¸»çŸ¥è¯†åº“æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not os.path.exists(main_knowledge_file):
                print(f"âš ï¸ ä¸»çŸ¥è¯†åº“æ–‡ä»¶ä¸å­˜åœ¨: {main_knowledge_file}")
                # å¦‚æœä¸å­˜åœ¨ï¼Œå°è¯•ä»fullæ–‡ä»¶è§£æ
                try:
                    full_file_path = os.path.join(self.data_dir, "strapi_knowledge_full.json")
                    if os.path.exists(full_file_path):
                        print(f"å°è¯•è§£æå…¨é‡æ–‡ä»¶: {full_file_path}")
                        self.parse_knowledge_json()
                    else:
                        print(f"âŒ æ‰¾ä¸åˆ°å…¨é‡çŸ¥è¯†åº“æ–‡ä»¶: {full_file_path}")
                        return False
                except Exception as e:
                    print(f"âŒ è§£æå…¨é‡æ–‡ä»¶å¤±è´¥: {str(e)}")
                    return False
            
            # å†æ¬¡æ£€æŸ¥ä¸»çŸ¥è¯†åº“æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not os.path.exists(main_knowledge_file):
                print(f"âŒ æ— æ³•åˆ›å»ºä¸»çŸ¥è¯†åº“æ–‡ä»¶")
                return False
        
            # è¯»å–ä¸»çŸ¥è¯†åº“æ–‡ä»¶
            with open(main_knowledge_file, 'r', encoding='utf-8') as f:
                main_data = json.load(f)
        
            print(f"ğŸ“š ä»ä¸»çŸ¥è¯†åº“åŠ è½½äº† {len(main_data)} æ¡è®°å½•")
        
            # è¯»å–æ–°å¢æ•°æ®æ–‡ä»¶
            new_data_path = new_data_file if os.path.isabs(new_data_file) else os.path.join(self.data_dir, new_data_file)
            with open(new_data_path, 'r', encoding='utf-8') as f:
                new_data_full = json.load(f)
        
            # ç¡®ä¿æ–°æ•°æ®æ˜¯æ­£ç¡®æ ¼å¼
            new_items = []
            if 'data' in new_data_full and isinstance(new_data_full['data'], list):
                new_items = new_data_full['data']
            else:
                print(f"âŒ æ–°å¢æ•°æ®æ–‡ä»¶æ ¼å¼ä¸æ­£ç¡®")
                return False
            
            print(f"ï¿½ï¿½ ä»å¢é‡æ–‡ä»¶åŠ è½½äº† {len(new_items)} æ¡è®°å½•")
        
            # åˆ›å»ºIDåˆ°æ•°æ®çš„æ˜ å°„ï¼Œä¾¿äºå¿«é€ŸæŸ¥æ‰¾å’Œæ›´æ–°
            id_to_index = {}
            for i, item in enumerate(main_data):
                if 'id' in item:
                    id_to_index[str(item['id'])] = i
        
            # å¤„ç†æ–°å¢/æ›´æ–°çš„è®°å½•
            updated_count = 0
            new_count = 0
        
            for item in new_items:
                item_id = str(item.get('id'))
                
                if not item_id:
                    print(f"âš ï¸ è·³è¿‡æ²¡æœ‰IDçš„è®°å½•")
                    continue
                
                # è½¬æ¢æ•°æ®æ ¼å¼
                attributes = item.get('attributes', {})
                faq = attributes.get('FAQ', '')
                
                parsed_item = {
                    'id': item_id,
                    'FAQ': faq if faq is not None else '',
                    'Keywords': attributes.get('Keywords', ''),
                    'Response': attributes.get('Response', '')
                }
                
                # æ£€æŸ¥æ˜¯å¦å­˜åœ¨ï¼Œå¦‚æœå­˜åœ¨åˆ™æ›´æ–°ï¼Œå¦åˆ™æ·»åŠ 
                if item_id in id_to_index:
                    main_data[id_to_index[item_id]] = parsed_item
                    updated_count += 1
                else:
                    main_data.append(parsed_item)
                    id_to_index[item_id] = len(main_data) - 1
                    new_count += 1
        
            # ä¿å­˜æ›´æ–°åçš„ä¸»çŸ¥è¯†åº“æ–‡ä»¶
            with open(main_knowledge_file, 'w', encoding='utf-8') as f:
                json.dump(main_data, f, ensure_ascii=False, indent=2)
        
            print(f"âœ… çŸ¥è¯†åº“æ–‡ä»¶æ›´æ–°æˆåŠŸ: æ›´æ–° {updated_count} æ¡, æ–°å¢ {new_count} æ¡")
            return True
        
        except Exception as e:
            print(f"âŒ æ›´æ–°çŸ¥è¯†åº“æ–‡ä»¶å¤±è´¥: {str(e)}")
            import traceback
            traceback.print_exc()
            return False

    def submit_feedback(self, feedback_id, good_or_bad, session_history, session_id):
        """
        æäº¤ç”¨æˆ·åé¦ˆåˆ°Strapi
        
        Args:
            feedback_id (str): åé¦ˆå”¯ä¸€æ ‡è¯†ç¬¦
            good_or_bad (bool): ç”¨æˆ·æ˜¯å¦æ»¡æ„å›ç­”
            session_history (list): ä¼šè¯å†å²è®°å½•
            session_id (str): ä¼šè¯ID
            
        Returns:
            tuple: (bool, str) - æˆåŠŸçŠ¶æ€å’Œæ¶ˆæ¯
        """
        try:
            # ä½¿ç”¨æœ¬åœ°Strapi URLå’Œè®¤è¯ä»¤ç‰Œ
            local_strapi_url = settings.LOCAL_STRAPI_API_URL.rstrip('/')
            local_strapi_token = settings.LOCAL_STRAPI_API_TOKEN
            
            # æœ¬åœ°Strapiçš„è¯·æ±‚å¤´
            local_headers = {
                "Authorization": f"Bearer {local_strapi_token}",
                "Content-Type": "application/json"
            }
            
            endpoint = "api/ai-support-session-feedbacks"
            url = f"{local_strapi_url}/{endpoint}"
            
            # è®°å½•æ¥æ”¶åˆ°çš„ä¼šè¯å†å²ä¿¡æ¯
            print(f"\nğŸ“‹ åœ¨strapi_serviceä¸­æ”¶åˆ°çš„ä¼šè¯å†å²:")
            print(f"ç±»å‹: {type(session_history)}")
            if isinstance(session_history, str):
                print(f"å·²æ˜¯JSONå­—ç¬¦ä¸²ï¼Œé•¿åº¦: {len(session_history)}")
                session_history_str = session_history
            else:
                print(f"Pythonå¯¹è±¡ï¼Œé•¿åº¦: {len(session_history) if hasattr(session_history, '__len__') else 'N/A'}")
                session_history_str = json.dumps(session_history)
            
            # æ„å»ºåé¦ˆæ•°æ®
            feedback_data = {
                "data": {
                    "feedback_id": feedback_id,
                    "good_or_bad": good_or_bad,
                    "session_history": session_history_str,
                    "session_id": session_id
                }
            }
            
            print(f"\nğŸ“¤ æäº¤åé¦ˆåˆ°æœ¬åœ°Strapi: {url}")
            print(f"åé¦ˆæ•°æ®: {feedback_data}")
            print(f"è¯·æ±‚å¤´: {local_headers}")
            
            # å‘é€POSTè¯·æ±‚åˆ°Strapiï¼Œä½¿ç”¨æœ¬åœ°è®¤è¯ä»¤ç‰Œ
            response = requests.post(
                url,
                json=feedback_data,
                headers=local_headers,
                timeout=10
            )
            
            # æ‰“å°å®Œæ•´çš„å“åº”å†…å®¹ä»¥ä¾¿è°ƒè¯•
            print(f"å“åº”çŠ¶æ€ç : {response.status_code}")
            print(f"å“åº”å†…å®¹: {response.text}")
            
            # æ£€æŸ¥å“åº”çŠ¶æ€
            response.raise_for_status()
            
            # è§£æå“åº”
            result = response.json()
            
            print(f"âœ… åé¦ˆæäº¤æˆåŠŸ: {result}")
            return True, "åé¦ˆæäº¤æˆåŠŸ"
            
        except requests.exceptions.RequestException as e:
            error_message = f"æäº¤åé¦ˆå¤±è´¥: {str(e)}"
            if hasattr(e, 'response') and e.response:
                error_message += f" - å“åº”çŠ¶æ€ç : {e.response.status_code}, å“åº”å†…å®¹: {e.response.text}"
            print(f"âŒ {error_message}")
            return False, error_message
        except Exception as e:
            error_message = f"æäº¤åé¦ˆå¤±è´¥: {str(e)}"
            print(f"âŒ {error_message}")
            return False, error_message

    def _get_embedding_function(self):
        """
        è·å–ä½¿ç”¨ OpenAI çš„ embedding å‡½æ•°
        
        Returns:
            callable: ç”¨äºåµŒå…¥çš„å‡½æ•°
        """
        print("åˆ›å»º OpenAI åµŒå…¥å‡½æ•°...")
        
        class OpenAIEmbeddingFunction:
            def __init__(self, parent):
                self.parent = parent
                self.openai_client = parent.openai_client
                # æ·»åŠ ç®€å•çš„å†…å­˜ç¼“å­˜ï¼Œé¿å…é‡å¤å¤„ç†ç›¸åŒæ–‡æœ¬
                self.cache = {}
                # å¯¼å…¥çº¿ç¨‹æ± 
                from concurrent.futures import ThreadPoolExecutor
                # å‡å°‘å·¥ä½œçº¿ç¨‹æ•°ä»¥æé«˜ç¨³å®šæ€§
                self.executor = ThreadPoolExecutor(max_workers=4) # ä»8å‡å°‘å›4
                
            def process_batch(self, batch):
                """å¤„ç†å•ä¸ªæ‰¹æ¬¡çš„æ–‡æœ¬"""
                max_retries = 3
                for retry in range(max_retries):
                    try:
                        start_time = time.time()
                        response = self.openai_client.embeddings.create(
                            model="text-embedding-ada-002",
                            input=batch,
                            timeout=5  # å‡å°‘è¶…æ—¶æ—¶é—´åˆ°5ç§’
                        )
                        embeddings = [item.embedding for item in response.data]
                        processing_time = time.time() - start_time
                        print(f"âœ… æ‰¹æ¬¡å¤„ç†å®Œæˆï¼Œè€—æ—¶: {processing_time:.2f}ç§’")
                        return embeddings
                    except Exception as e:
                        # æ£€æŸ¥æ˜¯å¦æ˜¯è¶…æ—¶é”™è¯¯
                        if "timeout" in str(e).lower() and retry < max_retries - 1:
                            wait_time = (retry + 1) * 5  # é€æ­¥å¢åŠ ç­‰å¾…æ—¶é—´
                            print(f"âš ï¸ æ‰¹æ¬¡å¤„ç†è¶…æ—¶ (å°è¯• {retry+1}/{max_retries})ï¼Œç­‰å¾… {wait_time} ç§’åé‡è¯•...")
                            time.sleep(wait_time)
                        else:
                            print(f"âŒ æ‰¹æ¬¡å¤„ç†å¤±è´¥: {str(e)}")
                            # è¿”å›é›¶å‘é‡ä½œä¸ºæ›¿ä»£
                            return [[0.0] * 1536 for _ in batch]
                return [[0.0] * 1536 for _ in batch]  # æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥æ—¶è¿”å›é›¶å‘é‡

            def __call__(self, input):
                """
                ä½¿ç”¨ OpenAI API ç”Ÿæˆæ–‡æœ¬åµŒå…¥
                
                Args:
                    input: è¦åµŒå…¥çš„æ–‡æœ¬åˆ—è¡¨
                
                Returns:
                    list: åµŒå…¥å‘é‡åˆ—è¡¨
                """
                if not input:
                    print("æ²¡æœ‰è¾“å…¥æ–‡æœ¬ï¼Œè¿”å›ç©ºåˆ—è¡¨")
                    return []
                    
                print(f"ä½¿ç”¨ OpenAI API ç”Ÿæˆ {len(input)} ä¸ªæ–‡æœ¬çš„åµŒå…¥å‘é‡...")
                
                # æ‰¹å¤„ç†ï¼Œå°è¯•æŠ˜ä¸­å¤§å°ä»¥å¹³è¡¡é€Ÿåº¦å’Œç¨³å®šæ€§
                batch_size = 50  # ä»100å‡å°‘åˆ°50
                all_embeddings = [None] * len(input)  # é¢„å…ˆåˆ†é…ç»“æœç©ºé—´
                
                # å¯¹æ–‡æœ¬è¿›è¡Œå»é‡å¤„ç†ï¼Œé¿å…é‡å¤è°ƒç”¨API
                unique_texts = {}
                for i, text in enumerate(input):
                    if text in self.cache:
                        # å¦‚æœå·²ç»åœ¨ç¼“å­˜ä¸­ï¼Œç›´æ¥ä½¿ç”¨
                        all_embeddings[i] = self.cache[text]
                    elif text in unique_texts:
                        # å¦‚æœå½“å‰æ‰¹æ¬¡ä¸­å·²æœ‰ç›¸åŒæ–‡æœ¬
                        unique_texts[text].append(i)
                    else:
                        # æ–°æ–‡æœ¬
                        unique_texts[text] = [i]
                
                # è¿‡æ»¤å‡ºéœ€è¦å¤„ç†çš„æ–°æ–‡æœ¬
                texts_to_process = list(unique_texts.keys())
                if not texts_to_process:
                    print("æ‰€æœ‰æ–‡æœ¬éƒ½åœ¨ç¼“å­˜ä¸­ï¼Œæ— éœ€è°ƒç”¨API")
                    return all_embeddings
                
                print(f"å»é‡åéœ€è¦å¤„ç† {len(texts_to_process)} ä¸ªå”¯ä¸€æ–‡æœ¬")
                
                try:
                    # åˆ†æ‰¹å¤„ç†
                    futures = []
                    for i in range(0, len(texts_to_process), batch_size):
                        batch = texts_to_process[i:i+batch_size]
                        batch_num = i//batch_size + 1
                        total_batches = (len(texts_to_process)-1)//batch_size + 1
                        print(f"æäº¤æ‰¹æ¬¡ {batch_num}/{total_batches}ï¼Œæ–‡æœ¬æ•°é‡ï¼š{len(batch)}")
                        
                        # å¹¶è¡Œæäº¤å¤„ç†ä»»åŠ¡
                        future = self.executor.submit(self.process_batch, batch)
                        futures.append((future, batch))
                    
                    # æ”¶é›†å¹¶å¤„ç†ç»“æœ
                    for (future, batch) in futures:
                        try:
                            # å¢åŠ ç­‰å¾…çº¿ç¨‹ç»“æœçš„è¶…æ—¶æ—¶é—´
                            batch_embeddings = future.result(timeout=10)  # ä»75ç§’å‡å°‘åˆ°10ç§’
                            # å°†ç»“æœä¿å­˜åˆ°ç¼“å­˜å’Œæœ€ç»ˆç»“æœ
                            for text, embedding in zip(batch, batch_embeddings):
                                self.cache[text] = embedding
                                # å°†ç»“æœåˆ†é…åˆ°å¯¹åº”ä½ç½®
                                for idx in unique_texts[text]:
                                    all_embeddings[idx] = embedding
                        except Exception as e:
                            print(f"è·å–æ‰¹æ¬¡ç»“æœå¤±è´¥: {str(e)}")
                            # å¯¹å¤±è´¥çš„æ‰¹æ¬¡ä½¿ç”¨é›¶å‘é‡
                            for text in batch:
                                zero_vector = [0.0] * 1536
                                self.cache[text] = zero_vector
                                for idx in unique_texts[text]:
                                    all_embeddings[idx] = zero_vector
                    
                    # ç¡®ä¿æ‰€æœ‰åµŒå…¥éƒ½å·²ç”Ÿæˆ
                    for i, embedding in enumerate(all_embeddings):
                        if embedding is None:
                            print(f"è­¦å‘Š: ç´¢å¼• {i} çš„åµŒå…¥æœªç”Ÿæˆï¼Œä½¿ç”¨é›¶å‘é‡")
                            all_embeddings[i] = [0.0] * 1536
                    
                    print(f"âœ… æˆåŠŸç”Ÿæˆ {len(all_embeddings)} ä¸ªåµŒå…¥å‘é‡")
                    return all_embeddings
                    
                except Exception as e:
                    print(f"âŒ åµŒå…¥ç”Ÿæˆè¿‡ç¨‹å¤±è´¥: {str(e)}")
                    print("è¿”å›é›¶å‘é‡ä½œä¸ºå¤‡é€‰æ–¹æ¡ˆ")
                    # å‡ºé”™æ—¶è¿”å›é›¶å‘é‡ä½œä¸ºå¤‡é€‰æ–¹æ¡ˆ
                    return [[0.0] * 1536 for _ in input]
        
        print("âœ… æˆåŠŸåˆ›å»º OpenAI åµŒå…¥å‡½æ•°")
        return OpenAIEmbeddingFunction(self)

    def clear_chromadb(self):
        """
        æ¸…ç©º ChromaDB ä¸­çš„æ‰€æœ‰é›†åˆæ•°æ®ï¼Œå¹¶å½»åº•æ¸…ç†ç£ç›˜æ–‡ä»¶
        
        Returns:
            bool: æ˜¯å¦æˆåŠŸæ¸…ç©º
        """
        try:
            print("\nğŸ—‘ï¸ å¼€å§‹æ¸…ç©º ChromaDB ä¸­çš„æ‰€æœ‰æ•°æ®...")
            
            # 1. é¦–å…ˆé€šè¿‡APIåˆ é™¤æ‰€æœ‰é›†åˆ
            collections = self.chroma_client.list_collections()
            
            if collections:
                print(f"ğŸ“Š å‘ç° {len(collections)} ä¸ªé›†åˆ: {[col.name for col in collections]}")
                
                for collection in collections:
                    collection_name = collection.name
                    print(f"ğŸ—‘ï¸ åˆ é™¤é›†åˆ '{collection_name}'...")
                    
                    try:
                        self.chroma_client.delete_collection(collection_name)
                        print(f"âœ… æˆåŠŸåˆ é™¤é›†åˆ '{collection_name}'")
                    except Exception as e:
                        print(f"âš ï¸ åˆ é™¤é›†åˆ '{collection_name}' å‡ºç°è­¦å‘Š: {str(e)}")
            else:
                print("â„¹ï¸ ChromaDB ä¸­æ²¡æœ‰é›†åˆ")
            
            # 2. ä½¿ç”¨resetæ–¹æ³•é‡ç½®æ•°æ®åº“ï¼Œè€Œä¸æ˜¯ç›´æ¥åˆ é™¤æ–‡ä»¶
            print("ğŸ“¤ é‡ç½® ChromaDB æ•°æ®åº“...")
            try:
                # å°è¯•ä½¿ç”¨reset API
                self.chroma_client.reset()
                print("âœ… æˆåŠŸä½¿ç”¨APIé‡ç½®ChromaDB")
            except Exception as e:
                print(f"âš ï¸ é‡ç½®APIå¤±è´¥ï¼Œå°†å°è¯•æ‰‹åŠ¨æ¸…ç†: {str(e)}")
                
            # 3. å…³é—­å®¢æˆ·ç«¯è¿æ¥
            print("ğŸ“¤ å…³é—­ ChromaDB å®¢æˆ·ç«¯è¿æ¥...")
            del self.chroma_client
            
            # 4. åªåˆ é™¤UUIDç›®å½•ï¼Œä¿ç•™sqliteæ•°æ®åº“æ–‡ä»¶
            print("ğŸ§¹ æ¸…ç† ChromaDB å‘é‡å­˜å‚¨ç›®å½•...")
            
            if os.path.exists(self.chroma_db_path):
                for item in os.listdir(self.chroma_db_path):
                    item_path = os.path.join(self.chroma_db_path, item)
                    try:
                        # åªåˆ é™¤ç›®å½•ï¼Œä¿ç•™sqliteæ–‡ä»¶
                        if os.path.isdir(item_path):
                            shutil.rmtree(item_path)
                            print(f"  âœ“ åˆ é™¤ç›®å½•: {item}")
                        # ä¸åˆ é™¤sqliteæ–‡ä»¶
                        elif item != "chroma.sqlite3":
                            os.unlink(item_path)
                            print(f"  âœ“ åˆ é™¤æ–‡ä»¶: {item}")
                        else:
                            print(f"  âš ï¸ ä¿ç•™æ•°æ®åº“æ–‡ä»¶: {item}")
                    except Exception as e:
                        print(f"  âœ— æ— æ³•åˆ é™¤ {item}: {str(e)}")
                
                # 5. ç¡®ä¿ç›®å½•æƒé™æ­£ç¡®
                print("ğŸ”’ è®¾ç½®æ­£ç¡®çš„ç›®å½•æƒé™...")
                os.chmod(self.chroma_db_path, 0o777)
                sqlite_path = os.path.join(self.chroma_db_path, "chroma.sqlite3")
                if os.path.exists(sqlite_path):
                    os.chmod(sqlite_path, 0o666)
                
                # ç­‰å¾…ä¸€ç§’ï¼Œç¡®ä¿æ–‡ä»¶ç³»ç»Ÿæ“ä½œå®Œæˆ
                time.sleep(1)
            
            # 6. é‡æ–°åˆå§‹åŒ–å®¢æˆ·ç«¯
            print("ğŸ”„ é‡æ–°åˆå§‹åŒ– ChromaDB å®¢æˆ·ç«¯...")
            self.chroma_client = chromadb.PersistentClient(
                path=self.chroma_db_path,
                settings=Settings(
                    anonymized_telemetry=False,
                    allow_reset=True,  # ç¡®ä¿å…è®¸é‡ç½®
                    persist_directory=self.chroma_db_path,
                    is_persistent=True
                )
            )
            
            print("âœ… æˆåŠŸæ¸…ç©º ChromaDB æ•°æ®")
            return True
            
        except Exception as e:
            print(f"âŒ æ¸…ç©º ChromaDB å¤±è´¥: {str(e)}")
            import traceback
            traceback.print_exc()
            
            # å°è¯•é‡æ–°åˆå§‹åŒ–å®¢æˆ·ç«¯
            try:
                print("ğŸ”„ å°è¯•é‡æ–°åˆå§‹åŒ– ChromaDB å®¢æˆ·ç«¯...")
                time.sleep(2)  # ç­‰å¾…2ç§’
                self.chroma_client = chromadb.PersistentClient(
                    path=self.chroma_db_path,
                    settings=Settings(
                        anonymized_telemetry=False,
                        allow_reset=True,
                        persist_directory=self.chroma_db_path,
                        is_persistent=True
                    )
                )
                print("âœ… é‡æ–°åˆå§‹åŒ– ChromaDB å®¢æˆ·ç«¯æˆåŠŸ")
            except Exception as e2:
                print(f"âŒ é‡æ–°åˆå§‹åŒ– ChromaDB å®¢æˆ·ç«¯å¤±è´¥: {str(e2)}")
            
            return False

# åˆ›å»º Strapi æœåŠ¡å®ä¾‹
strapi_service = StrapiService() 